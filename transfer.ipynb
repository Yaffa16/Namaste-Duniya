{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yaffa16/Namaste-Duniya/blob/master/transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPb_kaaYQgaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load = -1\n",
        "ss = 0.02 #Style loss multiplier\n",
        "\n",
        "from PIL import Image\n",
        "from math import floor, log2\n",
        "import numpy as np\n",
        "import time\n",
        "from functools import partial\n",
        "from random import random\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "#Lambdas\n",
        "def AdaIN(x):\n",
        "    #Normalize x[0]\n",
        "    mean = K.mean(x[0], axis = [1, 2], keepdims = True)\n",
        "    std = K.std(x[0], axis = [1, 2], keepdims = True) + 1e-7\n",
        "    y = (x[0] - mean) / std\n",
        "\n",
        "    #Reshape gamma and beta\n",
        "    pool_shape = [-1, 1, 1, y.shape[-1]]\n",
        "    g = K.reshape(x[1], pool_shape)\n",
        "    b = K.reshape(x[2], pool_shape)\n",
        "\n",
        "    #Multiply by x[1] (GAMMA) and add x[2] (BETA)\n",
        "    return y * g + b\n",
        "\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "\n",
        "def saveModel(model, name, num):\n",
        "    json = model.to_json()\n",
        "    with open(\"Models/\"+name+\".json\", \"w\") as json_file:\n",
        "        json_file.write(json)\n",
        "\n",
        "    model.save_weights(\"Models/\"+name+\"_\"+str(num)+\".h5\")\n",
        "\n",
        "def loadModel(name, num):\n",
        "\n",
        "    file = open(\"Models/\"+name+\".json\", 'r')\n",
        "    json = file.read()\n",
        "    file.close()\n",
        "\n",
        "    mod = model_from_json(json)\n",
        "    mod.load_weights(\"Models/\"+name+\"_\"+str(num)+\".h5\")\n",
        "\n",
        "    return mod\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Get encoder and representations\n",
        "vgg = VGG19(include_top=False, weights='imagenet')\n",
        "\n",
        "from datagen import dataGenerator, printProgressBar\n",
        "\n",
        "for i in range(len(vgg.layers)):\n",
        "    if vgg.layers[i].name == 'block4_conv1':\n",
        "        encoder = Model(vgg.input, vgg.layers[i].output)\n",
        "    if vgg.layers[i].name == 'block1_conv1':\n",
        "        rep1 = Model(vgg.input, vgg.layers[i].output)\n",
        "    if vgg.layers[i].name == 'block2_conv1':\n",
        "        rep2 = Model(vgg.input, vgg.layers[i].output)\n",
        "    if vgg.layers[i].name == 'block3_conv1':\n",
        "        rep3 = Model(vgg.input, vgg.layers[i].output)\n",
        "    if vgg.layers[i].name == 'block4_conv1':\n",
        "        rep4 = Model(vgg.input, vgg.layers[i].output)\n",
        "\n",
        "style_encoder = model_from_json(encoder.to_json())\n",
        "style_encoder.set_weights(encoder.get_weights())\n",
        "\n",
        "\n",
        "#Build decoder and style encoder\n",
        "if load < 0:\n",
        "    decoder = Sequential()\n",
        "    decoder.add(Conv2D(256, 3, activation='relu', padding='same', input_shape = [None, None, 512]))\n",
        "    decoder.add(UpSampling2D())\n",
        "    decoder.add(Conv2D(256, 3, activation='relu', padding='same'))\n",
        "    decoder.add(Conv2D(256, 3, activation='relu', padding='same'))\n",
        "    decoder.add(Conv2D(256, 3, activation='relu', padding='same'))\n",
        "    decoder.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
        "    decoder.add(UpSampling2D())\n",
        "    decoder.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
        "    decoder.add(Conv2D(64, 3, activation='relu', padding='same'))\n",
        "    decoder.add(UpSampling2D())\n",
        "    decoder.add(Conv2D(64, 3, activation='relu', padding='same'))\n",
        "    decoder.add(Conv2D(3, 3, activation='sigmoid', padding='same'))\n",
        "\n",
        "    inp = Input([None, None, 3])\n",
        "    x = style_encoder(inp)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation = 'relu')(x)\n",
        "    m = Dense(512)(x)\n",
        "    s = Dense(512)(x)\n",
        "\n",
        "    sencoder = Model(inp, [m, s])\n",
        "else:\n",
        "    decoder = loadModel(\"dec\", load)\n",
        "    sencoder = loadModel(\"sen\", load)\n",
        "\n",
        "\n",
        "\n",
        "#Loss functions\n",
        "def content_loss(y_true, y_pred, y_rep, sample_weight = None):\n",
        "    #Normalize prediction\n",
        "    mean = K.mean(y_pred, axis = [1, 2], keepdims = True)\n",
        "    std = K.std(y_pred, axis = [1, 2], keepdims = True) + 1e-7\n",
        "    yp = (y_pred - mean) / std\n",
        "\n",
        "    #Normalize representation\n",
        "    mean = K.mean(y_rep, axis = [1, 2], keepdims = True)\n",
        "    std = K.std(y_rep, axis = [1, 2], keepdims = True) + 1e-7\n",
        "    yr = (y_rep - mean) / std\n",
        "\n",
        "    #Find difference in normalized representations\n",
        "    return K.mean(K.square(yp - yr))\n",
        "\n",
        "def style_loss(y_true, y_pred, y_rep, weight = 1, sample_weight = None):\n",
        "    mean_loss = K.mean(y_pred, axis = [1, 2]) - K.mean(y_rep, axis = [1, 2])\n",
        "    mean_loss = K.square(mean_loss)\n",
        "    std_loss = K.std(y_pred, axis = [1, 2]) - K.std(y_rep, axis = [1, 2])\n",
        "    std_loss = K.square(std_loss)\n",
        "    return K.sum(K.mean(mean_loss + std_loss, axis = 0)) * weight\n",
        "\n",
        "\n",
        "#Training model\n",
        "content_image = Input([None, None, 3])\n",
        "style_image = Input([None, None, 3])\n",
        "\n",
        "content_rep = encoder(content_image)\n",
        "[smean, sstd] = sencoder(style_image)\n",
        "full_rep = Lambda(AdaIN)([content_rep, sstd, smean])\n",
        "\n",
        "decoded_image = decoder(full_rep)\n",
        "\n",
        "#Loss things\n",
        "\n",
        "s_loss1t = rep1(style_image)\n",
        "c_loss1t = rep1(content_image)\n",
        "loss1p = rep1(decoded_image)\n",
        "s_loss1 = partial(style_loss, y_rep = s_loss1t, weight = 100)\n",
        "c_loss1 = partial(content_loss, y_rep = c_loss1t)\n",
        "\n",
        "s_loss2t = rep2(style_image)\n",
        "c_loss2t = rep2(content_image)\n",
        "loss2p = rep2(decoded_image)\n",
        "s_loss2 = partial(style_loss, y_rep = s_loss2t, weight = 5)\n",
        "c_loss2 = partial(content_loss, y_rep = c_loss2t)\n",
        "\n",
        "s_loss3t = rep3(style_image)\n",
        "c_loss3t = rep3(content_image)\n",
        "loss3p = rep3(decoded_image)\n",
        "s_loss3 = partial(style_loss, y_rep = s_loss3t, weight = 0.8)\n",
        "c_loss3 = partial(content_loss, y_rep = c_loss3t)\n",
        "\n",
        "s_loss4t = rep4(style_image)\n",
        "c_loss4t = rep4(content_image)\n",
        "loss4p = rep4(decoded_image)\n",
        "s_loss4 = partial(style_loss, y_rep = s_loss4t, weight = 0.015)\n",
        "c_loss4 = partial(content_loss, y_rep = c_loss4t)\n",
        "\n",
        "#Model building\n",
        "\n",
        "model = Model([content_image, style_image], [loss1p, loss2p, loss3p, loss4p, loss1p, loss2p, loss3p, loss4p])\n",
        "eval_model = Model([content_image, style_image], decoded_image)\n",
        "\n",
        "eval_model.summary()\n",
        "\n",
        "encoder.trainable = False\n",
        "for layer in encoder.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "rep1.trainable = False\n",
        "for layer in rep1.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "rep2.trainable = False\n",
        "for layer in rep2.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "rep3.trainable = False\n",
        "for layer in rep3.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "rep4.trainable = False\n",
        "for layer in rep4.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "#Compilation\n",
        "model.compile(optimizer = Adam(lr = 0.0001),\n",
        "                loss = [c_loss1, c_loss2, c_loss3, c_loss4, s_loss1, s_loss2, s_loss3, s_loss4],\n",
        "                loss_weights = [1, 1, 1, 1, ss, ss, ss, ss])\n",
        "\n",
        "#Datasets\n",
        "coco = dataGenerator('coco', 256)\n",
        "wikiart = dataGenerator('wikiart', 256)\n",
        "\n",
        "#Evaluation function\n",
        "def evaluate(num = 0):\n",
        "    content_images = coco.get_batch(8)\n",
        "    style_images = wikiart.get_batch(8)\n",
        "\n",
        "    out_images = eval_model.predict([content_images, style_images], batch_size = 2)\n",
        "\n",
        "    r = []\n",
        "    for i in range(8):\n",
        "        r.append(np.concatenate([content_images[i], style_images[i], out_images[i]], axis = 1))\n",
        "\n",
        "    c = np.concatenate(r, axis = 0)\n",
        "\n",
        "    x = Image.fromarray(np.uint8(c * 255))\n",
        "    x.save(\"Results/e\" + str(num) + \".png\")\n",
        "\n",
        "#Training loop\n",
        "batch_size = 8\n",
        "for iteration in range(100000):\n",
        "    print(iteration, end = '\\r')\n",
        "    dummy = np.ones([batch_size, 1])\n",
        "    content_images = coco.get_batch(batch_size)\n",
        "    style_images = wikiart.get_batch(batch_size)\n",
        "    loss = model.train_on_batch([content_images, style_images], [dummy] * 8)\n",
        "\n",
        "    if iteration % 10 == 0:\n",
        "        print(loss)\n",
        "        evaluate(floor(iteration / 100))\n",
        "        saveModel(decoder, \"dec\", floor(iteration / 1000))\n",
        "        saveModel(sencoder, \"sen\", floor(iteration / 1000))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}