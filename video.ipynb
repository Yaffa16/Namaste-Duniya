{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yaffa16/Namaste-Duniya/blob/master/video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvDYAFYOQspm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vidname = 'vid.mp4'\n",
        "style = 's1.jpg'\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "\n",
        "model_num = 90\n",
        "\n",
        "vgg = VGG19(include_top=False, weights='imagenet')\n",
        "\n",
        "from datagen import dataGenerator, printProgressBar\n",
        "\n",
        "for i in range(len(vgg.layers)):\n",
        "    if vgg.layers[i].name == 'block4_conv1':\n",
        "        encoder = Model(vgg.input, vgg.layers[i].output)\n",
        "\n",
        "def loadModel(name, num):\n",
        "\n",
        "    file = open(\"Models/\"+name+\".json\", 'r')\n",
        "    json = file.read()\n",
        "    file.close()\n",
        "\n",
        "    mod = model_from_json(json)\n",
        "    mod.load_weights(\"Models/\"+name+\"_\"+str(num)+\".h5\")\n",
        "\n",
        "    return mod\n",
        "\n",
        "decoder = loadModel('dec', model_num)\n",
        "sencoder = loadModel('sen', model_num)\n",
        "\n",
        "#Lambdas\n",
        "def AdaIN(x):\n",
        "    #Normalize x[0]\n",
        "    mean = K.mean(x[0], axis = [1, 2], keepdims = True)\n",
        "    std = K.std(x[0], axis = [1, 2], keepdims = True) + 1e-7\n",
        "    y = (x[0] - mean) / std\n",
        "\n",
        "    #Reshape gamma and beta\n",
        "    pool_shape = [-1, 1, 1, y.shape[-1]]\n",
        "    g = K.reshape(x[1], pool_shape)\n",
        "    b = K.reshape(x[2], pool_shape)\n",
        "\n",
        "    #Multiply by x[1] (GAMMA) and add x[2] (BETA)\n",
        "    return y * g + b\n",
        "\n",
        "c_image = Input([None, None, 3])\n",
        "s_image = Input([None, None, 3])\n",
        "\n",
        "c_encoding = encoder(c_image)\n",
        "[smean, sstd] = sencoder(s_image)\n",
        "\n",
        "full_representation = AdaIN([c_encoding, sstd, smean])\n",
        "\n",
        "decoded_image = decoder(full_representation)\n",
        "\n",
        "model = Model([c_image, s_image], decoded_image)\n",
        "\n",
        "\n",
        "resize_content = False\n",
        "resize_style = True\n",
        "n = 0\n",
        "\n",
        "im2 = Image.open(style).convert('RGB')\n",
        "if resize_style:\n",
        "    im2 = im2.resize((256, 256), Image.BICUBIC)\n",
        "im2 = np.array(im2).astype('float32') / 255.0\n",
        "\n",
        "\n",
        "import cv2\n",
        "vidcap = cv2.VideoCapture(vidname)\n",
        "success,image = vidcap.read()\n",
        "count = 0\n",
        "size = (image.shape[1], image.shape[0])\n",
        "\n",
        "images = []\n",
        "style = []\n",
        "\n",
        "while success:\n",
        "    images.append(np.float32(image) / 255.0)\n",
        "    style.append(im2)\n",
        "    success,image = vidcap.read()\n",
        "    print('Read a new frame: ', count, end = '\\r')\n",
        "    count += 1\n",
        "\n",
        "print()\n",
        "\n",
        "images = np.array(images)\n",
        "style = np.array(style)\n",
        "\n",
        "output = model.predict([images, style], batch_size = 16, verbose = 1)\n",
        "output = np.uint8(output * 255)\n",
        "\n",
        "out = cv2.VideoWriter('project.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 30, size)\n",
        "\n",
        "for i in range(output.shape[0]):\n",
        "    #print(output[i].shape)\n",
        "    out.write(output[i])\n",
        "    print('Write frame: ', i, end = '\\r')\n",
        "\n",
        "out.release()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}